{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ecca05573ce9e71",
   "metadata": {},
   "source": [
    "# Automatizarea intocmirii fisei pacientului\n",
    "\n",
    "### Scop\n",
    "\n",
    "Dezvoltarea unui sistem inteligent care sƒÉ ajute medicii pentru a completa in mod automat fisa pacientului.\n",
    "\n",
    "### Ideea de baza\n",
    "\n",
    "Munca medicilor este plina de provocari. Mai ales cand trebuie sa faca multe task-uri, uneori simultan, precum realizarea si citirea unei ecografii si inregistrarea observatiilor facute. De aceea este nevoie de un sistem inteligent care sa transforme informatia audio inregistrata de catre un medic in format text si sa completeze in mod automat rubricile dedicate din fisa pacientului. Se va pleca de la inregistrari audio, se vor converti in format text si se va completa automat partea evidentiata cu galben din fisa pacientului (informatiile respective se vor salva intr-un tabel/jason si apoi se vor exporta intr-un document word)\n",
    "\n",
    "---\n",
    "\n",
    "### Descriere FormalƒÉ (MatematicƒÉ / TehnicƒÉ)\n",
    "\n",
    "Datele de intrare:\n",
    "ùëã = { fi»ôiere audio_i }\n",
    "- Explica»õie: X reprezintƒÉ mul»õimea fi»ôierelor audio √Ænregistrate de medic, fiecare corespunz√¢nd unei observa»õii sau consulta»õii.\n",
    "\n",
    "Scopul aplica»õiei:\n",
    "ùêπ: ùëã ‚Üí ùëå\n",
    "- Explica»õie: F este func»õia care transformƒÉ fi»ôierele audio √Æn fi»ôe pacient completate.\n",
    "\n",
    "Unde:\n",
    "ùëå = { fi»ôe pacient completate }\n",
    "- Explica»õie: Y este mul»õimea fi»ôelor completate cu informa»õii structurate extrase din audio.\n",
    "\n",
    "---\n",
    "\n",
    "### Descompunerea Problemei\n",
    "\n",
    "Problema poate fi descompusƒÉ √Æn douƒÉ sub-probleme:\n",
    "##### 1. Speech-to-Text\n",
    "ùëì‚ÇÅ : audio ‚Üí text\n",
    "- Explica»õie: f1 folose»ôte modele ASR (Romanian Wav2Vec2) pentru a transforma fi»ôierele audio √Æn text.\n",
    "##### 2. Information Extraction\n",
    "ùëì‚ÇÇ : text ‚Üí date structurate\n",
    "- Explica»õie: f2 extrage rubricile relevante din text pentru completarea automatƒÉ a fi»ôei pacientului.\n",
    "\n",
    "### Func»õia FinalƒÉ\n",
    "\n",
    "Func»õia finalƒÉ este:\n",
    "ùêπ = ùëì‚ÇÇ ‚àò ùëì‚ÇÅ\n",
    "- Explica»õie: mai √Ænt√¢i transformƒÉm audio-ul √Æn text, apoi extragem datele structurate pentru completarea fi»ôei pacientului.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-24T16:24:16.812542Z",
     "start_time": "2025-10-24T16:24:16.624881Z"
    }
   },
   "source": [
    "from fastapi import FastAPI, File, UploadFile\n",
    "from fastapi.responses import JSONResponse\n",
    "import shutil\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T16:24:22.941871Z",
     "start_time": "2025-10-24T16:24:16.825631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration, pipeline\n",
    "import soundfile as sf\n",
    "import torchaudio\n",
    "import torch\n",
    "\n",
    "model_name = \"TransferRapid/whisper-large-v3-turbo_ro\"\n",
    "\n",
    "# Load processor and model\n",
    "processor = WhisperProcessor.from_pretrained(model_name)\n",
    "model = WhisperForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "def preprocess_audio(audio_path, processor):\n",
    "    \"\"\"Preprocess audio: load via soundfile, resample if needed, and convert to model input format.\"\"\"\n",
    "    waveform_np, sample_rate = sf.read(audio_path)\n",
    "    waveform = torch.from_numpy(waveform_np).unsqueeze(0)\n",
    "\n",
    "    # Resample to 16kHz if needed\n",
    "    if sample_rate != 16000:\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
    "        waveform = resampler(waveform)\n",
    "\n",
    "    # Process audio into model input format\n",
    "    inputs = processor(waveform.squeeze().numpy(), sampling_rate=16000, return_tensors=\"pt\")\n",
    "\n",
    "    # Move inputs to device\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "\n",
    "    return inputs\n",
    "\n",
    "def transcribe(audio_path):\n",
    "    \"\"\"Generate transcription for an audio file.\"\"\"\n",
    "    inputs = preprocess_audio(audio_path, processor)\n",
    "\n",
    "    forced_decoder_ids = processor.tokenizer.get_decoder_prompt_ids(language=\"romanian\", task=\"transcribe\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(inputs[\"input_features\"], forced_decoder_ids=forced_decoder_ids)\n",
    "\n",
    "    transcription = processor.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "\n",
    "    return transcription[0]"
   ],
   "id": "3aa9e6272bd2b3e4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eduard/Development/MIRPR-Voice-To-Text/.venv1/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T16:24:23.043985Z",
     "start_time": "2025-10-24T16:24:23.041989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "app = FastAPI()\n",
    "UPLOAD_FOLDER = \"uploads\"\n",
    "os.makedirs(UPLOAD_FOLDER, exist_ok=True)"
   ],
   "id": "57cd455116d1d5fa",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T16:24:23.049821Z",
     "start_time": "2025-10-24T16:24:23.046932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@app.post(\"/upload-audio/\")\n",
    "async def upload_audio(file: UploadFile = File(...)):\n",
    "    file_path = os.path.join(UPLOAD_FOLDER, file.filename)\n",
    "    content = await file.read()\n",
    "    with open(file_path, \"wb\") as buffer:\n",
    "        buffer.write(content)\n",
    "    file_size = len(content)\n",
    "    transcription = transcribe(file_path)\n",
    "    return JSONResponse({\n",
    "        \"filename\": file.filename,\n",
    "        \"size_bytes\": file_size,\n",
    "        \"transcription\": transcription\n",
    "    })"
   ],
   "id": "12074219f8372a41",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T16:24:23.068576Z",
     "start_time": "2025-10-24T16:24:23.054475Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nest_asyncio\n",
    "import uvicorn\n",
    "import threading\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "def run_server():\n",
    "    uvicorn.run(app, host=\"127.0.0.1\", port=8000)\n",
    "\n",
    "thread = threading.Thread(target=run_server, daemon=True)\n",
    "thread.start()\n",
    "\n",
    "print(\"FastAPI server is running in the background on http://127.0.0.1:8000\")\n"
   ],
   "id": "625e28d948fc59c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastAPI server is running in the background on http://127.0.0.1:8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [407]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T16:24:35.624880Z",
     "start_time": "2025-10-24T16:24:23.123046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Manual/local test: pick first file from UPLOAD_FOLDER and transcribe\n",
    "import os\n",
    "files = os.listdir(UPLOAD_FOLDER)\n",
    "if not files:\n",
    "    print(\"No files found in uploads/ to transcribe.\")\n",
    "else:\n",
    "    test_path = os.path.join(UPLOAD_FOLDER, files[0])\n",
    "    print(f\"Testing file: {test_path}\")\n",
    "    try:\n",
    "        result = transcribe(test_path)\n",
    "        print(\"Local transcription:\", result)\n",
    "    except Exception as e:\n",
    "        print(f\"Error transcribing {test_path}: {e}\")\n"
   ],
   "id": "dcb3489479ddf63b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom `forced_decoder_ids` from the (generation) config. This is deprecated in favor of the `task` and `language` flags/config options.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing file: uploads/test3.ogg\n",
      "Local transcription: Aorta la inel, opt, aorta la sinusuri, doisprezece, aortƒÉ ascendentƒÉ, zece, a se treisprezece, vede, »ôase, vede, »ôase, vede, »ôase, vede, »ôase, vede, valva aorticƒÉ, valva aorticƒÉ, veice, treisprezece, barƒÉ »ôase, barƒÉ »ôase.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T16:24:47.470958Z",
     "start_time": "2025-10-24T16:24:35.719709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Local-only transcription test (no HTTP endpoints)\n",
    "local_audio_path = \"/Users/eduard/Downloads/test3.ogg\"  # adjust to your file\n",
    "print(f\"Loading and transcribing: {local_audio_path}\")\n",
    "try:\n",
    "    transcript = transcribe(local_audio_path)\n",
    "    print(\"Transcript:\", transcript)\n",
    "except Exception as e:\n",
    "    print(f\"Error during transcription: {e}\")\n"
   ],
   "id": "9b78995265aa4c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and transcribing: /Users/eduard/Downloads/test3.ogg\n",
      "Transcript: Aorta la inel, opt, aorta la sinusuri, doisprezece, aortƒÉ ascendentƒÉ, zece, a se treisprezece, vede, »ôase, vede, »ôase, vede, »ôase, vede, »ôase, vede, valva aorticƒÉ, valva aorticƒÉ, veice, treisprezece, barƒÉ »ôase, barƒÉ »ôase.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# === EXTRAC»öIE ENTITƒÇ»öI MEDICALE CU MODEL NER GENERIC (PENTRU COMPARA»öIE) ===\n",
    "import json\n",
    "CALEA_MODEL_NER = \"dumitrescustefan/bert-base-romanian-ner\"\n",
    "\n",
    "try:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"METODA 1: Model NER Generic (pentru referin»õƒÉ)\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\n‚ö†Ô∏è  AVERTISMENT: Modelul {CALEA_MODEL_NER} NU este antrenat pe date medicale!\")\n",
    "    print(\"    Rezultatele vor fi sub-optime pentru termeni medicali.\\n\")\n",
    "\n",
    "    # √éncƒÉrcƒÉm pipeline-ul NER generic\n",
    "    print(f\"Se √ÆncarcƒÉ modelul NER: {CALEA_MODEL_NER}...\")\n",
    "    ner_pipeline = pipeline(\n",
    "        \"ner\",\n",
    "        model=CALEA_MODEL_NER,\n",
    "        tokenizer=CALEA_MODEL_NER,\n",
    "        aggregation_strategy=\"simple\"\n",
    "    )\n",
    "    print(\"Model √ÆncƒÉrcat cu succes.\")\n",
    "\n",
    "    # RulƒÉm textul prin pipeline pentru a extrage entitƒÉ»õile\n",
    "    entitati_extrase = ner_pipeline(transcript)\n",
    "\n",
    "    print(\"\\n--- EntitƒÉ»õi Extrase de NER Generic ---\")\n",
    "    for entitate in entitati_extrase:\n",
    "        print(f\"- {entitate['entity_group']}: {entitate['word']} (scor: {entitate['score']:.2f})\")\n",
    "\n",
    "    # Conversia √Æn JSON Structurat\n",
    "    fisa_pacient_json_generic = {}\n",
    "    for entitate in entitati_extrase:\n",
    "        tip_entitate = entitate['entity_group']\n",
    "        valoare = entitate['word']\n",
    "        if tip_entitate not in fisa_pacient_json_generic:\n",
    "            fisa_pacient_json_generic[tip_entitate] = []\n",
    "        fisa_pacient_json_generic[tip_entitate].append(valoare)\n",
    "\n",
    "    print(\"\\n--- JSON Structurat Generat (Model Generic) ---\")\n",
    "    json_output_string = json.dumps(fisa_pacient_json_generic, indent=4, ensure_ascii=False)\n",
    "    print(json_output_string)\n",
    "\n",
    "    # Salvare √Æn fi»ôier\n",
    "    with open(\"fisa_pacient_output_generalist.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(json_output_string)\n",
    "    print(f\"\\nFi»ôierul 'fisa_pacient_output_generalist.json' a fost salvat.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"A apƒÉrut o eroare la √ÆncƒÉrcarea modelului sau la procesare: {e}\")\n"
   ],
   "id": "5634530f34a6f3b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# === EXTRAC»öIE ENTITƒÇ»öI MEDICALE CU EXTRACTOR SPECIALIZAT (RECOMANDAT) ===\n",
    "from medical_entity_extractor import MedicalEntityExtractor, process_medical_transcription\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"METODA 2: Extractor Medical Specializat (RECOMANDAT)\")\n",
    "print(\"=\" * 80)\n",
    "print(\"Folose»ôte pattern matching »ôi reguli specifice domeniului medical\\n\")\n",
    "\n",
    "# Ini»õializeazƒÉ extractorul\n",
    "extractor = MedicalEntityExtractor()\n",
    "\n",
    "# Extrage toate entitƒÉ»õile medicale\n",
    "fisa_pacient = extractor.extract_all_entities(transcript)\n",
    "\n",
    "# Afi»ôeazƒÉ rezultatele\n",
    "print(\"\\nMƒÇSURƒÇTORI ECOGRAFICE EXTRASE:\")\n",
    "print(\"-\" * 80)\n",
    "if fisa_pacient.masuratori_ecografice:\n",
    "    for i, masurare in enumerate(fisa_pacient.masuratori_ecografice, 1):\n",
    "        print(f\"{i}. {masurare['structura_anatomica']}: {masurare['valoare_numerica']} {masurare['unitate_masura']}\")\n",
    "else:\n",
    "    print(\"   Nicio mƒÉsurƒÉtoare detectatƒÉ\")\n",
    "\n",
    "print(\"\\nüíä MEDICAMENTE EXTRASE:\")\n",
    "print(\"-\" * 80)\n",
    "if fisa_pacient.medicamente:\n",
    "    for med in fisa_pacient.medicamente:\n",
    "        print(f\"   ‚Ä¢ {med['nume']} - {med['dozaj']} ({med['frecventa']})\")\n",
    "else:\n",
    "    print(\"   Niciun medicament detectat\")\n",
    "\n",
    "print(\"\\nü©∫ SIMPTOME EXTRASE:\")\n",
    "print(\"-\" * 80)\n",
    "if fisa_pacient.simptome:\n",
    "    for simptom in fisa_pacient.simptome:\n",
    "        print(f\"   ‚Ä¢ {simptom}\")\n",
    "else:\n",
    "    print(\"   Niciun simptom detectat\")\n",
    "\n",
    "print(\"\\nDIAGNOSTICE EXTRASE:\")\n",
    "print(\"-\" * 80)\n",
    "if fisa_pacient.diagnostice:\n",
    "    for diagnostic in fisa_pacient.diagnostice:\n",
    "        print(f\"   ‚Ä¢ {diagnostic}\")\n",
    "else:\n",
    "    print(\"   Niciun diagnostic detectat\")\n",
    "\n",
    "# SalveazƒÉ √Æn format JSON standard\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SALVARE DATE STRUCTURATE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "extractor.save_to_json(fisa_pacient, \"fisa_pacient_medical_structured.json\")\n",
    "\n",
    "# GenereazƒÉ »ôi salveazƒÉ format FHIR\n",
    "fhir_observations = extractor.to_fhir_observation(fisa_pacient.masuratori_ecografice)\n",
    "with open(\"fhir_observations.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(fhir_observations, f, indent=4, ensure_ascii=False)\n",
    "print(f\"Observa»õii FHIR salvate √Æn: fhir_observations.json\")\n",
    "\n",
    "# Afi»ôeazƒÉ JSON-ul complet\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"JSON COMPLET (cu format FHIR)\")\n",
    "print(\"=\" * 80)\n",
    "print(extractor.to_json(fisa_pacient))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PROCESARE COMPLETƒÇ!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nFI»òIERE GENERATE:\")\n",
    "print(\"   1. fisa_pacient_medical_structured.json  - Date structurate complete\")\n",
    "print(\"   2. fhir_observations.json                - Format FHIR pentru integrare\")\n",
    "print(\"   3. fisa_pacient_output_generalist.json   - Rezultat model NER generic (pentru compara»õie)\")\n",
    "print(\"\\nTIP: Folose»ôte 'fisa_pacient_medical_structured.json' pentru generarea raportului Word!\")\n"
   ],
   "id": "6a8455c72fdafd41"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# === GENERARE RAPORT WORD (CONFORM SEC»öIUNII 5.2 DIN GHID) ===\n",
    "from word_report_generator import MedicalReportGenerator, generate_word_report\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"GENERARE RAPORT WORD AUTOMAT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Metoda 1: Raport simplu (fƒÉrƒÉ »ôablon)\n",
    "print(\"\\nGenerare raport simplu...\")\n",
    "try:\n",
    "    raport_path = generate_word_report(\n",
    "        json_path=\"fisa_pacient_medical_structured.json\",\n",
    "        output_path=f\"raport_medical_{datetime.now().strftime('%Y%m%d_%H%M%S')}.docx\",\n",
    "        use_template=False\n",
    "    )\n",
    "    print(f\"Raport generat: {raport_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Eroare la generarea raportului: {e}\")\n",
    "\n",
    "# Metoda 2: Raport cu »ôablon personalizat\n",
    "print(\"\\nGenerare »ôablon Word personalizabil...\")\n",
    "generator = MedicalReportGenerator()\n",
    "try:\n",
    "    generator.create_template(\"template_fisa_pacient.docx\")\n",
    "\n",
    "    # GenereazƒÉ raport folosind »ôablonul\n",
    "    print(\"\\nGenerare raport din »ôablon...\")\n",
    "    raport_template_path = generate_word_report(\n",
    "        json_path=\"fisa_pacient_medical_structured.json\",\n",
    "        output_path=f\"raport_medical_template_{datetime.now().strftime('%Y%m%d_%H%M%S')}.docx\",\n",
    "        use_template=True,\n",
    "        template_path=\"template_fisa_pacient.docx\"\n",
    "    )\n",
    "    print(f\"Raport din »ôablon generat: {raport_template_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Eroare la generarea raportului cu »ôablon: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PIPELINE COMPLET FINALIZAT!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nREZULTATE FINALE:\")\n",
    "print(\"   Audio ‚Üí Text (ASR cu Whisper)\")\n",
    "print(\"   Text ‚Üí EntitƒÉ»õi Structurate (Pattern Matching Medical)\")\n",
    "print(\"   EntitƒÉ»õi ‚Üí JSON (cu format FHIR)\")\n",
    "print(\"   JSON ‚Üí Raport Word (Formatat »ôi Lizibil)\")\n",
    "print(\"\\nURMƒÇTORII PA»òI:\")\n",
    "print(\"   1. EditeazƒÉ template_fisa_pacient.docx √Æn Word pentru personalizare\")\n",
    "print(\"   2. Fine-tuning model NER pentru domeniul medical (op»õional, pentru acurate»õe maximƒÉ)\")\n",
    "print(\"   3. IntegreazƒÉ cu sistemul medical existent (FHIR, HL7)\")\n"
   ],
   "id": "60172c83a523078c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
